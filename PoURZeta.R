rm(list=ls())
require(dplyr)
require(zetadiv)
wd <- "~/Desktop/eDNA-metadata/"
#wd <- "/home1/alsimons/PoUR"
setwd(wd)
set.seed(1)

#Get environmental files generated by extracting environmental metadata from Google Earth.
GoogleEarthFiles <- list.files(path=wd,pattern='eedataPoURRound')

#Get basic metadata files for the eDNA sampling locations
PoURMetadataFiles <- list.files(path=wd,pattern='PoURMetadataRound')

#Read in environmental metadata descriptions and categories.
MetadataCategory <- read.table("PoURMetadataExplanation.csv", header=TRUE, sep=",",as.is=T,skip=0,fill=TRUE,check.names=FALSE,quote = "\"", encoding = "UTF-8",allowEscapes=T)

#Input taxonomic level to aggregate on.  Rank 7 is the most resolved, and Rank 1 is the least.
rank=7

#Iterate over sample rounds and primer sets.
#Calculate zeta_4 and how much of the variation in it is due to variations
#in geographic separation, environmental variations, or some unknown factor.
#Calculate the relative likelihoods of an exponential versus power-law decay model
#in zeta_N for N=1,4.
#Primers
Primers <- c("16S", "18S","CO1","VERT12S","PITS","FITS")
#
zetaAnalysis <- data.frame()
zetaVarAnalysis <- data.frame()
ZetaMax <- 4
for(i in 3:3){
  for(Primer in Primers){
    #Get basic metadata for the eDNA sampling locations
    PoURMetadataInput <- read.table(PoURMetadataFiles[i], header=TRUE, sep=",",as.is=T,skip=0,fill=TRUE,check.names=FALSE,quote = "\"", encoding = "UTF-8",allowEscapes=T)
    #Remove control samples
    PoURMetadataInput <- PoURMetadataInput[PoURMetadataInput$Sample_or_Control=="Sample" & PoURMetadataInput$Date_Collected!="Control",]
    
    #Keep only certain columns for analysis.
    PoURMetadataInput <- PoURMetadataInput[,c("Sample","Latitude","Longitude","Substrate","Site","River_Bottom","Biofilm","Habitat","Depth","Features")]
    #Coerce coorindates to be numeric.
    PoURMetadataInput$Latitude <- as.numeric(PoURMetadataInput$Latitude)
    PoURMetadataInput$Longitude <- as.numeric(PoURMetadataInput$Longitude)
    #Only keep sediment samples.
    PoURMetadataInput <- PoURMetadataInput[PoURMetadataInput$Substrate=="Sediment",]
    #Convert character columns to factors.
    PoURMetadataInput[sapply(PoURMetadataInput, is.character)] <- lapply(PoURMetadataInput[sapply(PoURMetadataInput, is.character)], as.factor)
    #Coerce sample name back to character prior to merging.
    PoURMetadataInput$Sample <- as.character(PoURMetadataInput$Sample)
    
    #Get environmental metadata generated by extracting environmental metadata from Google Earth.
    GoogleEarthInput <- read.table(GoogleEarthFiles[i], header=TRUE, sep=",",as.is=T,skip=0,fill=TRUE,check.names=FALSE,quote = "\"", encoding = "UTF-8",allowEscapes=T)
    #Remove extraneous columns
    GoogleEarthInput$us_l3name <- NULL
    GoogleEarthInput$latitude <- NULL
    GoogleEarthInput$longitude <- NULL
    #Remove control samples.
    GoogleEarthInput <- GoogleEarthInput[GoogleEarthInput$name %in% PoURMetadataInput$Sample,]
    
    #Merge metadata data frames.
    PoURMetadata <- dplyr::left_join(PoURMetadataInput,GoogleEarthInput,by=c("Sample"="name"))
    #Get a list of environmental variables.
    EnvVar <- colnames(PoURMetadata)
    #Remove sample ID from environmental variable list.
    EnvVar <- EnvVar[!(EnvVar %in% c("Sample","Substrate","Biofilm","Latitude","Longitude"))]
    #Add sample name to row names.
    rownames(PoURMetadata) <- PoURMetadata$Sample
    #Remove rows with missing data.
    PoURMetadata <- PoURMetadata[complete.cases(PoURMetadata),]
    
    #Get samples classified using a particular primer.
    SampleFiles <- list.files(path=wd,pattern=paste("_physeq_",Primer,"_dct_noblanks_min20p",sep=""))
    
    #Set taxonomic rank column names.
    TaxonomicRanks <- c("Rank1", "Rank2","Rank3","Rank4","Rank5","Rank6","Rank7")
    #Set selected taxonomic rank for analysis.
    TaxonomicRank <- paste("Rank",rank,sep="")
    #Read in sample data classified using a selected primer.
    SampleInput <- read.table(SampleFiles[i], header=TRUE, sep="\t",as.is=T,skip=0,fill=TRUE,check.names=FALSE,quote = "\"", encoding = "UTF-8",allowEscapes=T)
    #Standardize column name
    colnames(SampleInput)<-gsub(paste("R",i,"_",sep=""),"",colnames(SampleInput))
    #Remove control samples from eDNA data.
    SampleInput <- SampleInput[,colnames(SampleInput) %in% c(PoURMetadata$Sample,"sum.taxonomy")]
    #Split taxonomy names into their component ranks.
    SampleInput <- suppressWarnings(tidyr::separate(SampleInput,'sum.taxonomy',TaxonomicRanks,sep=";", extra="drop"))
    #Standardize NA values
    SampleInput[SampleInput=="NA"] <- NA
    SampleInput[SampleInput==""] <- NA
    #Remove all taxonomic rank column except the selected one.
    SampleInput <- SampleInput[, !(names(SampleInput) %in% TaxonomicRanks[!(TaxonomicRanks %in% TaxonomicRank)])]
    #Remove all rows with missing taxonomic data.
    SampleInput <- SampleInput[!is.na(SampleInput[,TaxonomicRank]),]
    #Aggregate sequence reads by taxonomic groups.
    SampleInput <- as.data.frame(aggregate(formula(paste0(". ~ ",TaxonomicRank)),SampleInput,sum,na.action = na.omit))
    #Move taxonomy to row names.
    rownames(SampleInput) <- SampleInput[,TaxonomicRank]
    SampleInput[,TaxonomicRank] <- NULL
    #Remove samples with fewer than 2000 read sequences per sample,
    #and found in more than one and less than all of the samples.
    SampleInput <- SampleInput[,(colSums(SampleInput) > 2000) & colSums(SampleInput != 0) > 1 & colSums(SampleInput != 0) < nrow(SampleInput)]
    #Convert sequence abundance to presence/absence.  Remove singletons and doubletons.
    SampleInput[SampleInput <= 2] <- 0
    SampleInput[SampleInput > 2] <- 1
    #Take the transpose so that the columns are taxa, and the rows are samples.
    SampleInput <- as.data.frame(t(SampleInput))
    #Remove species columns if they only show up in one sample, or in every sample
    SampleInput <- SampleInput[,colSums(SampleInput) > 1 & colSums(SampleInput) < nrow(SampleInput)]
    #Get the list of unique taxonomic groups.
    taxa <- colnames(SampleInput)
    for(site in unique(PoURMetadata$Site)){
      #Get environmental metadata for a site.
      SiteEnv <- PoURMetadata[PoURMetadata$Site==site,]
      #Get samples within a site.
      SiteSamples <- SampleInput[rownames(SampleInput) %in% SiteEnv$Sample,]
      if(nrow(SiteSamples)>ZetaMax){
        #Get mean human impact per site.
        SitegHM <- mean(SiteEnv[rownames(SiteEnv) %in% rownames(SiteSamples),"gHM"],na.rm=T)
        #Run zeta diversity decay on the samples per site.
        zetaDecay <- Zeta.decline.ex(SiteSamples,orders=1:ZetaMax,rescale=T,plot=F)
        #Calculate the relative likelihoods of exponential and power-law decay models for zeta diversity per site.
        ExpAIC <- zetaDecay$aic$AIC[1] #AIC coefficient Zeta diversity exponential decay.
        PLAIC <- zetaDecay$aic$AIC[2] #AIC coefficient Zeta diversity power law decay.
        deltaAIC <- ExpAIC-PLAIC
        dataRow <- (as.data.frame(list(Primer,i,site,SitegHM,ExpAIC,PLAIC,deltaAIC)))
        colnames(dataRow) <- c("Primer","SampleRound","Site","gHM","ExpAIC","PLAIC","deltaAIC")
        rownames(dataRow) <- NULL
        zetaAnalysis <- rbind(zetaAnalysis,dataRow)
        print(paste(Primer,i,site,SitegHM,ExpAIC,PLAIC,deltaAIC)) 
      }
    }
    if(nrow(SampleInput)>length(EnvVar)){
      data.spec <- SampleInput[order(row.names(SampleInput)),]
      data.xy <- PoURMetadata[rownames(PoURMetadata) %in% rownames(SampleInput),c("Latitude","Longitude")]
      data.xy <- data.xy[order(row.names(data.xy)),]
      for(Variable in unique(MetadataCategory$Variable)){
        data.env <- as.data.frame(PoURMetadata[rownames(PoURMetadata) %in% rownames(SampleInput),Variable])
        #Zeta.varpart returns a data frame with one column containing the variation explained by each component 
        #a (the variation explained by distance alone),
        #b (the variation explained by either distance or the environment),
        #c (the variation explained by the environment alone) and 
        #d (the unexplained variation).
        zetaVariation <- Zeta.varpart(Zeta.msgdm(data.spec=data.spec,data.env=data.env,xy=data.xy,order=ZetaMax,method.glm="glm.fit.cons",distance.type="ortho",normalize=FALSE,rescale=FALSE),num.part=2,method.glm="glm.fit.cons")
        zetaVarRow <- as.data.frame(list(Primer,i,Variable,zetaVariation[4,],zetaVariation[6,],zetaVariation[7,]))
        colnames(zetaVarRow) <- c("Primer","SampleRound","Variable","VariationFromDistance","VariationFromEnvironment","VariationUnknown")
        rownames(zetaVarRow) <- NULL
        zetaVarAnalysis <- rbind(zetaVarAnalysis,zetaVarRow)
        print(paste(Primer,i,Variable,zetaVariation[4,],zetaVariation[6,],zetaVariation[7,]))
      }
    }
  }
}
zetaAnalysis <- zetaAnalysis[!is.infinite(zetaAnalysis$ExpAIC),]
write.table(zetaAnalysis,"PoURZetaAssembly.txt",quote=FALSE,sep="\t",row.names = FALSE)
write.table(zetaVarAnalysis,"PoURZetaFactors.txt",quote=FALSE,sep="\t",row.names = FALSE)
